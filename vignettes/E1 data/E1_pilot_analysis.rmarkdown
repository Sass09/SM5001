---
title: "E1 Pilot"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{E1_DF_Mixed}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```


Data collected 3/2/23

# Load libraries


```{r}
library(dplyr)
library(tidyverse)
library(jsonlite)
library(xtable)
library(data.table)
```


## Import Data


```{r}
# Read the text file from JATOS ...
read_file('jatos_results_20230426163309.txt') %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
  # ... filter empty rows ...
  discard(function(x) x == '') %>%
  # ... parse JSON into a data.frame
  map_dfr(fromJSON, flatten=T) -> all_data
```


## Demographics


```{r}
library(tidyr)

demographics <- all_data %>%
  filter(trial_type == "survey-html-form") %>%
  select(ID,response) %>%
  unnest_wider(response) %>%
  mutate(age = as.numeric(age))

age_demographics <- demographics %>%
  summarize(mean_age = mean(age),
            sd_age = sd(age),
            min_age = min(age),
            max_age = max(age))

factor_demographics <- apply(demographics[-1], 2, table)

```


A total of `r dim(demographics)[1]` participants were recruited from Amazon's Mechanical Turk. Mean age was `r round(age_demographics$mean_age, digits=1)` (range = `r age_demographics$min_age` to `r age_demographics$max_age` ). There were `r as.numeric(factor_demographics$sex["female"])` females, and `r as.numeric(factor_demographics$sex["male"])` males. There were `r as.numeric(factor_demographics$hand["Right"])` right-handed participants, and `r as.numeric(factor_demographics$hand["Both"])+as.numeric(factor_demographics$hand["Left"])` left or both handed participants. `r as.numeric(factor_demographics$vision["Normal"])` participants reported normal vision, and `r as.numeric(factor_demographics$vision["Corrected"])` participants reported corrected-to-normal vision. `r as.numeric(factor_demographics$english["First"])` participants reported English as a first language, and `r as.numeric(factor_demographics$english["Second"])` participants reported English as a second language.

## Pre-processing

### Case judgment accuracy


```{r}
case_judgment <- all_data %>%
  filter(encoding_trial_type == "study_word",
         study_instruction == "case") %>%
  mutate(response = as.character(unlist(response))) %>%
  mutate(accuracy = case_when(
    response == "0" & letter_case == "upper" ~ 1,
    response == "1" & letter_case == "upper" ~ 0,
    response == "0" & letter_case == "lower" ~ 0,
    response == "1" & letter_case == "lower" ~ 1
         )) %>%
  group_by(ID) %>%
  summarise(percent_correct = mean(accuracy))

ggplot(case_judgment, aes(x=percent_correct))+
  geom_histogram() +
  geom_vline(xintercept=.7)
```


## All exclusions


```{r}
all_excluded <- case_judgment %>%
  filter(percent_correct < .7) %>%
  select(ID) %>%
  pull()

length(all_excluded)

filtered_data <- all_data %>%
  filter(ID %in% all_excluded == FALSE)

```


# Accuracy analysis

## Define Helper functions

To do, consider moving the functions into the R package for this project


```{r}
# attempt general solution

## Declare helper functions

################
# get_mean_sem
# data = a data frame
# grouping_vars = a character vector of factors for analysis contained in data
# dv = a string indicated the dependent variable colunmn name in data
# returns data frame with grouping variables, and mean_{dv}, sem_{dv}
# note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv

get_mean_sem <- function(data, grouping_vars, dv, digits=3){
  a <- data %>%
    group_by_at(grouping_vars) %>%
    summarize("mean_{ dv }" := round(mean(.data[[dv]]), digits),
              "sem_{ dv }" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),
              .groups="drop")
  return(a)
}

################
# get_effect_names
# grouping_vars = a character vector of factors for analysis
# returns a named list
# list contains all main effects and interaction terms
# useful for iterating the computation means across design effects and interactions

get_effect_names <- function(grouping_vars){
  effect_names <- grouping_vars
  if( length(grouping_vars > 1) ){
    for( i in 2:length(grouping_vars) ){
      effect_names <- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=":"))
    }
  }
  effects <- strsplit(effect_names, split=":")
  names(effects) <- effect_names
  return(effects)
}

################
# print_list_of_tables
# table_list = a list of named tables
# each table is printed 
# names are header level 3

print_list_of_tables <- function(table_list){
  for(i in 1:length(table_list)){
    cat("###",names(table_list[i]))
    cat("\n")
    print(knitr::kable(table_list[[i]]))
    cat("\n")
  }
}
```


## Design mutation


```{r}


```


## Conduct Analysis


```{r}
# get response bias

response_bias <-  all_data %>%
  filter(encoding_trial_type == "study_word") %>%
  mutate(response = as.character(unlist(response))) %>%
  group_by(ID,study_instruction) %>%
  count(response)


```


## Study phase recall


```{r}

study_phase_recall <-  filtered_data %>%
  filter(phase == "study_recall",
         encoding_recall == "recall") %>%
  separate(col = paragraph,
           into = c("first_word","second_word"),
           sep = " ",
           remove = FALSE,
           extra = "merge") %>%
  mutate(accuracy = tolower(target_word) == tolower(first_word)) %>%
  group_by(ID,study_instruction) %>%
  summarize(percent_correct = mean(accuracy))

```


## recall


```{r}
recall_data <- filtered_data %>%
  filter(phase %in% c("recall_1","recall_2") == TRUE ) %>%
  select(ID,phase,paragraph) %>%
  pivot_wider(names_from = phase,
              values_from = paragraph) %>%
  mutate(recall_1 = paste(recall_1,recall_2,sep = " ")) %>%
  select(ID,recall_1) %>%
 # separate_longer_delim(cols = recall_1,
 #                        delim = " ") %>%
  mutate(recall_1 = tolower(recall_1)) %>%
  mutate(recall_1 = gsub("[^[:alnum:][:space:]]","",recall_1))

encoding_words_per_subject <- filtered_data %>%
  filter(encoding_trial_type == "study_word",
         phase == "main_study")

encoding_words_by_recall <- left_join(encoding_words_per_subject,recall_data,by = 'ID') %>%
  mutate(recall_1 = strsplit(recall_1," "))

recall_success <- c()
min_string_distance <- c()
for(i in 1:dim(encoding_words_by_recall)[1]){
  recalled_words <- unlist(encoding_words_by_recall$recall_1[i])
  recalled_words <- recalled_words[recalled_words != ""]
  if (length(recalled_words) == 0 ) recalled_words <- "nonerecalled"
  recall_success[i] <- tolower(encoding_words_by_recall$target_word[i]) %in% recalled_words
  min_string_distance[i] <- min(sapply(recalled_words,FUN = function(x) {
  stringdist::stringdist(a=x,b = tolower(encoding_words_by_recall$target_word[i]), method = "lv")
}))
}



encoding_words_by_recall <- encoding_words_by_recall %>%
  mutate(recall_success = recall_success,
         min_string_distance = min_string_distance) %>%
  mutate(close_recall = min_string_distance <= 2) %>%
  group_by(ID,study_instruction,encoding_recall,block_type) %>%
  summarise(number_recalled = sum(recall_success),
            number_close_recalled = sum(close_recall))

mean_encoding_words_by_recall <- encoding_words_by_recall %>%
  group_by(study_instruction,encoding_recall,block_type) %>%
  summarise(mean_recall = mean(number_recalled),
            mean_close_recall = mean(number_close_recalled))

```


# Data plots

## Predictions


```{r}

prediction_graph <- tibble(
  `Hypothesis` = rep(c("H1: Retrieval Practice \n Improves Recall \n for Case and Semantic","H2: Retrieval Practice \n Improves Recall \n For All"),each=6),
  `Study Instruction` = factor(rep(c("Case","Semantic","Self","Case","Semantic","Self"),2),
                                  levels= c("Case","Semantic","Self")),
  `Retrieval Practice` = rep(rep(c("No Retrieval Practice \n during study \n", "Retrieval Practice \n during study \n"),each =3),2),
  `Predicted Recall` = c(1,2,3,3,3,3,1,2,3,2,3,4)
  )


ggplot(prediction_graph,aes(x=`Study Instruction`, 
                            y = `Predicted Recall`, 
                            fill = `Retrieval Practice`)) +
  geom_bar(stat="identity", position="dodge", color="black") +
  facet_wrap(~`Hypothesis`) +
  ylab("Predicted # Words Recalled") +
  theme_classic(base_size = 15)


```


## Main Findings


```{r}

findings <- get_mean_sem(encoding_words_by_recall,
             c("study_instruction","encoding_recall"),
             "number_recalled") 

findings <- findings %>% 
  mutate(study_instruction = factor(study_instruction,levels = c("case","semantic","self")),
         `Retrieval Practice` = case_when(
           encoding_recall == "no_recall" ~ "No Retrieval Practice \n during study \n",
           encoding_recall == "recall" ~ "Retrieval Practice \n during study \n",
                                          ))


ggplot(findings,
       aes(x=study_instruction,
           y=mean_number_recalled,
           fill=`Retrieval Practice`))+
  geom_bar(stat="identity",position="dodge",color="black") +
  geom_errorbar(aes(ymin = mean_number_recalled-sem_number_recalled,
                    ymax = mean_number_recalled+sem_number_recalled),
                width=.9, position=position_dodge2(width = 0.2, padding = 0.8)) +
  ylab("Mean # of Words Recalled")+
  xlab("Study Instruction") +
  theme_classic(base_size = 15)


```


### More plots


```{r}

mean_exact_recall <- get_mean_sem(encoding_words_by_recall,
             c("study_instruction","encoding_recall","block_type"),
             "number_recalled")

ggplot(mean_exact_recall,
       aes(x=study_instruction,
           y=mean_number_recalled,
           group = encoding_recall,
           fill= encoding_recall))+
  geom_bar(stat="identity",position="dodge")+
  geom_errorbar(aes(ymin = mean_number_recalled-sem_number_recalled,
                    ymax = mean_number_recalled+sem_number_recalled),
                width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+
  facet_wrap(~block_type)

mean_close_recall <- get_mean_sem(encoding_words_by_recall,
             c("study_instruction","encoding_recall","block_type"),
             "number_close_recalled")

ggplot(mean_close_recall,
       aes(x=study_instruction,
           y=mean_number_close_recalled,
           group = encoding_recall,
           fill=encoding_recall))+
  geom_bar(stat="identity",position="dodge") +
  geom_errorbar(aes(ymin = mean_number_close_recalled-sem_number_close_recalled,
                    ymax = mean_number_close_recalled+sem_number_close_recalled),
                width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+
  facet_wrap(~block_type)


recall_no_recall <- get_mean_sem(encoding_words_by_recall,
             c("encoding_recall"),
             "number_close_recalled")

ggplot(recall_no_recall,
       aes(x=encoding_recall,
           y=mean_number_close_recalled))+
  geom_bar(stat="identity",position="dodge") +
  geom_errorbar(aes(ymin = mean_number_close_recalled-sem_number_close_recalled,
                    ymax = mean_number_close_recalled+sem_number_close_recalled),
                width=.9, position=position_dodge2(width = 0.2, padding = 0.8))

study_instruction <- get_mean_sem(encoding_words_by_recall,
             c("study_instruction"),
             "number_close_recalled")

ggplot(study_instruction,
       aes(x=study_instruction,
           y=mean_number_close_recalled))+
  geom_bar(stat="identity",position="dodge") +
  geom_errorbar(aes(ymin = mean_number_close_recalled-sem_number_close_recalled,
                    ymax = mean_number_close_recalled+sem_number_close_recalled),
                width=.9, position=position_dodge2(width = 0.2, padding = 0.8))


```

